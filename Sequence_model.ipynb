{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from preprocess import preprocessor\n",
    "from preprocess import clean_df\n",
    "from preprocess import define_vocab_to_remove\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\quent\\OneDrive\\Bureau\\NLP\\NLP_project\\preprocess.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data[\"title\"] = filtered_data[\"title\"].astype(str)\n",
      "c:\\Users\\quent\\OneDrive\\Bureau\\NLP\\NLP_project\\preprocess.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data[\"title\"] = filtered_data[\"title\"].astype(str)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"labelled_newscatcher_dataset.csv\", sep=\";\")\n",
    "data\n",
    "\n",
    "sample_data = data.sample(n=10000, random_state=42).reset_index(drop=True)\n",
    "sample_X,sample_y = clean_df(sample_data)\n",
    "\n",
    "X,y = clean_df(data)\n",
    "words_to_remove = define_vocab_to_remove(X)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(sample_X,sample_y,test_size=0.2)\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    X_train.iloc[i] = preprocessor(X_train.iloc[i], words_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = ['SCIENCE', 'TECHNOLOGY', 'HEALTH', 'WORLD', 'ENTERTAINMENT', 'SPORTS', 'BUSINESS', 'NATION']\n",
    "\n",
    "label_encoder = LabelEncoder() # instantiate a label encoder \n",
    "y_train_enc = label_encoder.fit_transform(y_train)\n",
    "y_test_enc = label_encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.vocab import Vocab\n",
    "from torch.utils.data import DataLoader, TensorDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reset_index(drop=True)\n",
    "\n",
    "full_text = ' '.join(X_train)\n",
    "split_text = full_text.split()\n",
    "set_split_text = set(split_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitleClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, nb_classes):\n",
    "        super(TitleClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim,hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim,nb_classes)\n",
    "\n",
    "    def forward(self,X):\n",
    "        embedded = self.embedding(X)\n",
    "        output , _ = self.rnn(embedded)\n",
    "        last_hidden = output[:, -1, :]\n",
    "        logits = self.fc(last_hidden)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         joe biden kamala harri say trump left us tatter\n",
       "1            liz hurley son damian spot gal pal wear jean\n",
       "2               atletico report two posit coronaviru test\n",
       "3                  smart tv come roku here that bad thing\n",
       "4       wechat ban could impact appl global iphon ship...\n",
       "                              ...                        \n",
       "7995          fall billboard injur two heavi rain karachi\n",
       "7996    pj polic 19yearold allegedli gang rape seven s...\n",
       "7997    california megachurch draw thousand inperson s...\n",
       "7998     pandit jasraj tribut ar rahman shabana azmi star\n",
       "7999    russian weightlift alexand sedykh break knee 4...\n",
       "Name: title, Length: 8000, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         joe biden kamala harri say trump left us tatter\n",
       "1            liz hurley son damian spot gal pal wear jean\n",
       "2               atletico report two posit coronaviru test\n",
       "3                  smart tv come roku here that bad thing\n",
       "4       wechat ban could impact appl global iphon ship...\n",
       "                              ...                        \n",
       "7995          fall billboard injur two heavi rain karachi\n",
       "7996    pj polic 19yearold allegedli gang rape seven s...\n",
       "7997    california megachurch draw thousand inperson s...\n",
       "7998     pandit jasraj tribut ar rahman shabana azmi star\n",
       "7999    russian weightlift alexand sedykh break knee 4...\n",
       "Name: title, Length: 8000, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'joe biden kamala harri say trump left us tatter'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\quent\\OneDrive\\Bureau\\NLP\\NLP_project\\Sequence_model.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/quent/OneDrive/Bureau/NLP/NLP_project/Sequence_model.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/quent/OneDrive/Bureau/NLP/NLP_project/Sequence_model.ipynb#X10sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mAdam(Model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mlearning_rate)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/quent/OneDrive/Bureau/NLP/NLP_project/Sequence_model.ipynb#X10sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m X_train_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(X_train\u001b[39m.\u001b[39;49mastype(\u001b[39mint\u001b[39;49m), dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/quent/OneDrive/Bureau/NLP/NLP_project/Sequence_model.ipynb#X10sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m y_enc_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(y_train_enc[:\u001b[39m1000\u001b[39m], dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/quent/OneDrive/Bureau/NLP/NLP_project/Sequence_model.ipynb#X10sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m train_data \u001b[39m=\u001b[39m TensorDataset(X_train, y_train_enc)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:6534\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6530\u001b[0m     results \u001b[39m=\u001b[39m [ser\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy) \u001b[39mfor\u001b[39;00m _, ser \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems()]\n\u001b[0;32m   6532\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   6533\u001b[0m     \u001b[39m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6534\u001b[0m     new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mastype(dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   6535\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[39m=\u001b[39mnew_data\u001b[39m.\u001b[39maxes)\n\u001b[0;32m   6536\u001b[0m     \u001b[39mreturn\u001b[39;00m res\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mastype\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:414\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    411\u001b[0m \u001b[39melif\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    412\u001b[0m     copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m--> 414\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply(\n\u001b[0;32m    415\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mastype\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    416\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    417\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    418\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    419\u001b[0m     using_cow\u001b[39m=\u001b[39;49musing_copy_on_write(),\n\u001b[0;32m    420\u001b[0m )\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:354\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    352\u001b[0m         applied \u001b[39m=\u001b[39m b\u001b[39m.\u001b[39mapply(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 354\u001b[0m         applied \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(b, f)(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    355\u001b[0m     result_blocks \u001b[39m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    357\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mfrom_blocks(result_blocks, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:616\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors, using_cow)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    597\u001b[0m \u001b[39mCoerce to the new dtype.\u001b[39;00m\n\u001b[0;32m    598\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[39mBlock\u001b[39;00m\n\u001b[0;32m    613\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    614\u001b[0m values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues\n\u001b[1;32m--> 616\u001b[0m new_values \u001b[39m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m    618\u001b[0m new_values \u001b[39m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    620\u001b[0m refs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:238\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    235\u001b[0m     dtype \u001b[39m=\u001b[39m dtype\u001b[39m.\u001b[39mnumpy_dtype\n\u001b[0;32m    237\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 238\u001b[0m     new_values \u001b[39m=\u001b[39m astype_array(values, dtype, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[0;32m    239\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n\u001b[0;32m    240\u001b[0m     \u001b[39m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[39m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    242\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:183\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    180\u001b[0m     values \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m    182\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 183\u001b[0m     values \u001b[39m=\u001b[39m _astype_nansafe(values, dtype, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[0;32m    185\u001b[0m \u001b[39m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, np\u001b[39m.\u001b[39mdtype) \u001b[39mand\u001b[39;00m \u001b[39missubclass\u001b[39m(values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:134\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[0;32m    132\u001b[0m \u001b[39mif\u001b[39;00m copy \u001b[39mor\u001b[39;00m arr\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m \u001b[39mobject\u001b[39m \u001b[39mor\u001b[39;00m dtype \u001b[39m==\u001b[39m \u001b[39mobject\u001b[39m:\n\u001b[0;32m    133\u001b[0m     \u001b[39m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39;49mastype(dtype, copy\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    136\u001b[0m \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'joe biden kamala harri say trump left us tatter'"
     ]
    }
   ],
   "source": [
    "vocab_size = len(set_split_text)\n",
    "embedding_dim = 100\n",
    "hidden_dim = 64\n",
    "nb_classes = 8\n",
    "batch_size = 32\n",
    "nb_epochs = 5\n",
    "learning_rate = 0.001\n",
    "\n",
    "Model = TitleClassifier(vocab_size, embedding_dim, hidden_dim, nb_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(Model.parameters(), lr=learning_rate)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train.astype(int), dtype=torch.long)\n",
    "y_enc_tensor = torch.tensor(y_train_enc[:1000], dtype=torch.long)\n",
    "\n",
    "train_data = TensorDataset(X_train, y_train_enc)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "for epoch in range(nb_epochs):\n",
    "    Model.train()\n",
    "    for text,y in train_data:\n",
    "        optimizer.zero_grad()\n",
    "        output = Model(text)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (4) must match the size of tensor b (32) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\quent\\OneDrive\\Bureau\\NLP\\NLP_project\\Sequence_model.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/quent/OneDrive/Bureau/NLP/NLP_project/Sequence_model.ipynb#X11sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         _, predicted_labels \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(outputs, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/quent/OneDrive/Bureau/NLP/NLP_project/Sequence_model.ipynb#X11sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m         total_test_samples \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(text)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/quent/OneDrive/Bureau/NLP/NLP_project/Sequence_model.ipynb#X11sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m         correct_predictions \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (predicted_labels \u001b[39m==\u001b[39;49m torch\u001b[39m.\u001b[39;49mtensor(y_test_enc[:\u001b[39m32\u001b[39;49m]))\u001b[39m.\u001b[39msum()\u001b[39m.\u001b[39mitem()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/quent/OneDrive/Bureau/NLP/NLP_project/Sequence_model.ipynb#X11sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m accuracy \u001b[39m=\u001b[39m correct_predictions \u001b[39m/\u001b[39m total_test_samples\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/quent/OneDrive/Bureau/NLP/NLP_project/Sequence_model.ipynb#X11sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mprint\u001b[39m(accuracy)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (32) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "X_test_tensor = torch.tensor(X_test.toarray(), dtype=torch.long)\n",
    "test_loader = DataLoader(X_test_tensor, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "Model.eval()\n",
    "with torch.no_grad():\n",
    "    total_test_samples = 0\n",
    "    correct_predictions = 0\n",
    "    for text in test_loader:\n",
    "        text = torch.LongTensor(text)\n",
    "        outputs = Model(text)\n",
    "\n",
    "        _, predicted_labels = torch.max(outputs, dim=1)\n",
    "\n",
    "        total_test_samples += len(text)\n",
    "        correct_predictions += (predicted_labels == torch.tensor(y_test_enc[:32])).sum().item()\n",
    "\n",
    "accuracy = correct_predictions / total_test_samples\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
